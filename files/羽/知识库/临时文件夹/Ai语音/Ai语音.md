# Ai语音 Overview
 ==**让任何人都能自由的发声**==
 你的天籁之音
 在万众瞩目中飘扬
 在无数欢呼中放送
 而我
 只敢用低音应和
 我也想要大声歌唱
 我羡慕你的音色
 我羡慕你能够大声的发声
 我偷不走你天使吻过的嗓子
 我只能
 偷走你的声音
 我很抱歉
 我也想要能够自由的发声
 我很抱歉
 
```ccard
type: folder_brief_live
```

两条路线, rvc(改变音色), vits(生成声音)
vits 集大成[链接](https://www.bilibili.com/video/BV1hp4y1K78E/)
rvc 集大成[链接](https://www.bilibili.com/video/BV1pm4y1z7Gm/)

新出的gpt vits[链接](https://www.bilibili.com/video/BV12g4y1m7Uw/)
这个是集成两家之长?拥有rvc的简单和易用, 又有vits的效果

**==草，使用colab过程中不要切换gpu状态，省nmd时间呢，他会直接把全部文件全部进程清掉！！！**==
我真的是草了

## GPT-Vits

### 处理数据
#### 提取人声
使用自带的UVR5处理音频
1. 先用HP2模型处理一遍(提取人声)
2. 将输出的干声音频再用onnx_dereverb
	1. 在这一步, 音频文件会被归类到非人声文件, 注意不要删错了.
3. 最后用DeEcho-Aggressive(去混响), 输出格式选wav
	1. 输出的文件默认在GPT-SoVITS-beta\GPT-SoVITS-beta\output\uvr5_opt这个文件夹下，处理完的音频（vocal）的是人声，(instrument)是伴奏，(No Reverb)的没混响的，（Reverb）的是混响。（vocal）(No Reverb)才是要用的文件，其他都可以删除。结束后记得到WebUI关闭UVR5节省显存。
效果不好的话可以使用au, 收藏夹-提取人声后在将噪音作为噪声捕捉, 在进行人声提取

最后声音记得调整到-6--9(分贝)之间
![[提取人声#提取人声 Overview]]

#### 切割音频
min_length根据显存大小调整，显存越小调越小。min_interval根据音频的平均间隔调整，如果音频太密集可以适当调低。max_sil_kept会影响句子的连贯性，不同音频不同调整，不会调的话保持默认。其他参数不建议调整。
切分完后文件在\GPT-SoVITS-beta\GPT-SoVITS-beta\output\slicer_opt。打开切分文件夹，排序方式选大小，将时长超过 显存数 秒的音频手动切分至 显存数 秒以下。
### 清洗数据
打标
打标就是给每个音频配上文字
#### 自动处理大部分
只要把刚才的切分文件夹输入，默认是output/slicer_opt文件夹。然后选择达摩ASR或者fast whisper。达摩ASR只能用于识别中文，效果也最好。fast whisper可以标注99种语言，是目前最好的英语和日语识别，模型尺寸选large V3，语种选auto自动就好了。然后点**开启离线批量ASR**就好了，默认输出是output/asr_opt这个路径，ASR需要一些时间，看着控制台有没有报错就好了

如果有字幕的可以用字幕标注，准确多了。内嵌字幕或者外挂字幕都可以，教程[使用字幕标注（更准确）](https://www.yuque.com/baicaigongchang1145haoyuangong/ib3g1e/pqn7zn003kduyye2?singleDoc# "使用字幕标注（更准确）")
![](https://cdn.nlark.com/yuque/0/2024/png/42546880/1707523954744-806ac45d-1f0c-46b7-be3b-c7b70a1da697.png)

#### 手动处理小部分(追求精准)
输入标注文件的文件路径，然后开启打标webui, 进行手动修改
### 载入和格式化数据
进入1A 训练集格式化工具
1. 设置模型名
2. 输入标注文件路径
3. 输入切割后的音频文件路径
4. **一键三连**即可
### 开始训练
进入1B 微调训练界面
#### 几个主要的参数
vits轮数可以尽可能高
gpt轮数在一般情况下默认即可(15): 在无同语言语料的情况下, 可以尝试调高轮数
学习率权重: 可以调低但不建议调高
batch_size: 显存的一半, 然后根据切片长度进行调整, 普通切片(5s左右)再减少一半, 如果大于5s继续减少, 小于5s可以增加
	看大小是否合适? 打开任务管理器, 显存不要100%占用(太多了,调小), 要在90%左右为佳
	个人实测 3060 6g 3s切片可以使用bs=2/3
能开**dpo训练**就开(能够提供更高的上限, 但是要求有优秀的训练集)
中途结束的话可以从最近存档点开始(不要删除\GPT-SoVITS-beta\SoVITS_weights路径下的最新模型, 检测到最新的符合训练集名字的模型的轮数小于设定轮数, 将会从这个模型开始继续训练)